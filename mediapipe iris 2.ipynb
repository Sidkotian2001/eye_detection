{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73b4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import math\n",
    "from playsound import playsound\n",
    "import time\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615e52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "distances = []\n",
    "focii = []\n",
    "message = None\n",
    "colour = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fe83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]\n",
    "RIGHT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_IRIS = [469, 470, 471, 472]\n",
    "RIGHT_IRIS = [474, 475, 476, 477]\n",
    "CENTERS = [468, 473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1575616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_commands():\n",
    "    texts = ['Go right', 'Go left', 'Go up', 'Go down', 'Get closer', 'Stay in Square']\n",
    "    language = 'en'\n",
    "    for text in texts:\n",
    "        text_obj = gTTS(text = text, lang = language, slow = False)\n",
    "        text_obj.save(f'{text}.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd5eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install_commands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e9ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, face):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = face.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001fd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(coord1, coord2):\n",
    "    \n",
    "    irises_dist_in_pixels = math.dist(coord1, coord2)\n",
    "    irises_dist_in_rw = 7\n",
    "    face_dist_in_rw = 80\n",
    "    focal_length = (irises_dist_in_pixels * face_dist_in_rw) / irises_dist_in_rw\n",
    "    focii.append(focal_length)\n",
    "    \n",
    "    \n",
    "    #focal length for distance = 70cm is 611cm\n",
    "    #focal length for distance = 60cm is 618cm\n",
    "    #focal length for distance = 50cm is 602cm\n",
    "    #focal length for distance = 40cm is 610cm\n",
    "    #average focal length = 610.25cm\n",
    "    \n",
    "    avg_focal_length = 610\n",
    "    actual_distance = (avg_focal_length * irises_dist_in_rw) / irises_dist_in_pixels\n",
    "    distances.append(actual_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a9a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_detection(part, facial_landmarks, image_shape):\n",
    "    idx_to_coordinates = {}\n",
    "    img_height, img_width, _ = image_shape\n",
    "    for idx, landmark in enumerate(part):\n",
    "        coord = facial_landmarks.landmark[landmark]\n",
    "        \n",
    "        p_x = min(math.floor(coord.x * img_width), img_width - 1)\n",
    "        p_y = min(math.floor(coord.y * img_height), img_height - 1)\n",
    "        landmark_coord = (p_x, p_y)\n",
    "        \n",
    "        if landmark_coord:\n",
    "            idx_to_coordinates[idx] = landmark_coord\n",
    "    return idx_to_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7d1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_part(image, coords, color, show_landmarks = False, center_coords = False):\n",
    "    points = np.zeros(shape = (len(coords), 2))\n",
    "    for idx, landmark_px in coords.items():\n",
    "        points[idx] = landmark_px\n",
    "        if show_landmarks == True:\n",
    "            cv.circle(image, landmark_px, 1, (255, 0, 0), 2)\n",
    "    points = points.astype(np.int32)\n",
    "    \n",
    "    #Only for center coordinates\n",
    "    if center_coords == False:\n",
    "        cv.polylines(image, [points], True, color, 2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6360490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bool_array(x1, y1, x2, y2):\n",
    "    arr = []\n",
    "    for i in range(x1, x2):\n",
    "        for j in range(y1, y2):\n",
    "            arr.append((i,j))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57980971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_regions(image):\n",
    "    #creating frame lines\n",
    "    cv.line(image, (0, 240), (640, 240), (255,0,255), 1)\n",
    "    cv.line(image, (320, 0), (320, 480), (255,0,255), 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c6e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound(count):\n",
    "    msgs = ['Go left', 'Go right', 'Go up', 'Go down', 'Stay in Square', 'Get closer']\n",
    "    init_time = time.time()\n",
    "    current_time = 0\n",
    "    current2_time = time.time()\n",
    "    print(\"hello\")\n",
    "    while count.value != -1:\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - init_time > 3:\n",
    "            playsound(\"{}.mp3\".format(msgs[count.value]))\n",
    "            init_time = time.time()\n",
    "            print(\"sound:\", msgs[count.value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbaf24b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_position(image, center_coords, count):\n",
    "    \n",
    "    #sound messages\n",
    "    msgs = ['Go left', 'Go right', 'Go up', 'Go down', 'Stay in Square', 'Get closer']\n",
    "    \n",
    "    \n",
    "    #getting the distances\n",
    "    ideal_dist = 50\n",
    "    actual_dist = distances[-1]\n",
    "    \n",
    "    #message to be displayed\n",
    "    \n",
    "    \n",
    "    #left rectangle\n",
    "    left_x1, left_y1 = 220, 210\n",
    "    left_x2, left_y2 = 300, 270\n",
    "    \n",
    "    #right_rectangle\n",
    "    right_x1, right_y1 = 340, 210\n",
    "    right_x2, right_y2 = 420, 270\n",
    "    \n",
    "    left_center_x = center_coords[0][0]\n",
    "    left_center_y = center_coords[0][1]\n",
    "    \n",
    "    right_center_x = center_coords[1][0]\n",
    "    right_center_y = center_coords[1][1]\n",
    "    \n",
    "    arr1 = create_bool_array(left_x1, left_y1, left_x2, left_y2)\n",
    "    arr2 = create_bool_array(right_x1, right_y1, right_x2, right_y2)\n",
    "    \n",
    "    if  (left_center_x, left_center_y) in arr1 and (right_center_x, right_center_y) in arr2:\n",
    "        #message = \"Stay in Square\"\n",
    "        count.value = 4\n",
    "        colour = (0,255,0)\n",
    "        \n",
    "        if actual_dist > ideal_dist:\n",
    "            #message = \"Get closer\"\n",
    "            count.value = 5\n",
    "            colour = (0, 0, 255)\n",
    "        \n",
    "        cv.rectangle(image, (left_x1, left_y1), (left_x2, left_y2), colour, 1)\n",
    "        cv.rectangle(image, (right_x1, right_y1), (right_x2, right_y2), colour, 1)\n",
    "    \n",
    "    else:\n",
    "        colour = (0,0,255)\n",
    "        cv.rectangle(image, (left_x1, left_y1), (left_x2, left_y2), colour, 1)\n",
    "        cv.rectangle(image, (right_x1, right_y1), (right_x2, right_y2), colour, 1)\n",
    "        \n",
    "        if left_center_x < left_x1 or right_center_x < right_x1:\n",
    "            #message = \"Go right\"\n",
    "            count.value = 1\n",
    "                        \n",
    "        elif left_center_x > left_x2 or right_center_x > right_x2:\n",
    "            #message = \"Go left\"\n",
    "            count.value = 0\n",
    "            \n",
    "        elif left_center_y < left_y1 or right_center_y < right_y1:\n",
    "            #message = \"Go down\"\n",
    "            count.value = 3\n",
    "            \n",
    "        elif left_center_y > left_y2 or right_center_y > right_y2:\n",
    "            # message = \"Go up\"\n",
    "            count.value = 2   \n",
    "\n",
    "    cv.putText(image, msgs[count.value], (200, 100), cv.FONT_HERSHEY_SIMPLEX, 1, colour, 2, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc93a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correct_position(image, facial_landmarks, center, center_coords):\n",
    "#     print(center_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5800b068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def capture(cap, count):\n",
    "#     cap = cv.VideoCapture(0)\n",
    "    message = None\n",
    "    initial_time = time.time()\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces = 1,\n",
    "        refine_landmarks = True,\n",
    "        min_detection_confidence = 0.5,\n",
    "        min_tracking_confidence = 0.5\n",
    "    ) as face_mesh:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            current_time = time.time()\n",
    "            if not ret:\n",
    "                print(\"Not ret\")\n",
    "                break\n",
    "\n",
    "\n",
    "            image = cv.flip(frame, 1)\n",
    "            image, results = mediapipe_detection(image, face_mesh)\n",
    "            img_height, img_width, _ = image.shape\n",
    "\n",
    "    #             print(image.shape)\n",
    "            if results.multi_face_landmarks:\n",
    "                for num, facial_landmarks in enumerate(results.multi_face_landmarks):\n",
    "\n",
    "                    left_eye_coords = part_detection(LEFT_EYE, facial_landmarks, image.shape)\n",
    "                    right_eye_coords = part_detection(RIGHT_EYE, facial_landmarks, image.shape)\n",
    "    #                 left_iris_coords = part_detection(LEFT_IRIS, facial_landmarks, image.shape)\n",
    "    #                 right_iris_coords = part_detection(RIGHT_IRIS, facial_landmarks, image.shape)\n",
    "                    centers_coords = part_detection(CENTERS, facial_landmarks, image.shape)\n",
    "\n",
    "\n",
    "                    display_part(image, left_eye_coords, (0,255,255), False)\n",
    "                    display_part(image, right_eye_coords, (0,255,255), False)\n",
    "    #                 display_part(image, left_iris_coords, (0,255,255), True)\n",
    "    #                 display_part(image, right_iris_coords, (0,255,255), True)\n",
    "                    display_part(image, centers_coords, (0,255,255), True, True)\n",
    "\n",
    "            display_regions(image)\n",
    "            get_distance(centers_coords[0], centers_coords[1])\n",
    "\n",
    "\n",
    "            correct_position(image, centers_coords, count)\n",
    "\n",
    "            cv.imshow(\"video feed\", image)\n",
    "            if cv.waitKey(5) & 0xff == ord('q'):\n",
    "                count.value = -1\n",
    "                break\n",
    "    print(sum(distances) / len(distances))\n",
    "    print(distances[-1])\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87331bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     install_commands()\n",
    "    cap = cv.VideoCapture(0)\n",
    "    count = multiprocessing.Value('i')\n",
    "    \n",
    "    p1 = multiprocessing.Process(target = capture, args = (cap, count))\n",
    "    p2 = multiprocessing.Process(target = play_sound, args = (count, ))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    \n",
    "    print(\"finsihed session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64380b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound: Go right\n",
      "sound: Go down\n",
      "sound: Stay in Square\n",
      "sound: Go right\n",
      "sound: Go left\n",
      "sound: Go down\n",
      "54.47134612615369\n",
      "71.8688213257567\n",
      "finsihed session\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247fdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
